ğŸ“š Multi-Project Repository

This repository contains four major Python projects developed for data analysis, modeling, and benchmarking:

1. NumPy Neural Network for Regression â€“ Fully connected neural network built from scratch for regression tasks.
2. Streamlit NLP Dashboard â€“ Interactive text analysis and visualization.
3. Time-Series Benchmarking â€“ Performance comparison of rolling operations using Pandas, NumPy, and Numba. 
4. Stock Price Data Cleaning & Logistic Regression Modeling â€“ Data preprocessing, feature engineering, and predictive modeling on stock market data.

1ï¸âƒ£ NumPy Neural Network for Regression

ğŸ“Œ Overview

Implements a fully connected feedforward neural network from scratch using NumPy:

* Configurable activation functions (`ReLU`, `Sigmoid`)
* Manual forward & backward propagation
* **SGD optimizer** with mini-batch training
* Mean Squared Error loss
* Synthetic cubic function regression task

ğŸ“‚ Structure


numpy_nn/
â”œâ”€â”€ model.py              # NeuralNetwork and SGD classes
â”œâ”€â”€ train.py              # Training script on synthetic data


ğŸš€ Run

bash
python train.py


ğŸ“¦ Requirements

Install all dependencies with:

bash
pip install -r requirements.txt


requirements.txt

streamlit
matplotlib
pandas
nltk
numpy
numba
seaborn
scikit-learn
statsmodels


2ï¸âƒ£ Streamlit NLP Dashboard

ğŸ“Œ Overview
A two-page Streamlit application for text analytics, allowing:
- Uploading `.txt` files
- Viewing top word frequencies
- Extracting collocations (bigrams)
- Computing sentiment scores
- POS tagging and distribution charts

ğŸ“‚ Structure


nlp\_dashboard/
â”œâ”€â”€ app\_analysis.py       # Page 1: Frequency, collocations, sentiment
â”œâ”€â”€ app\_explorer.py       # Page 2: POS tagging and DataFrame explorer
â”œâ”€â”€ nlp\_pipeline.py       # NLP helper functions



ğŸš€ Run
bash
pip install -r requirements.txt
streamlit run app_analysis.py
# OR
streamlit run app_explorer.py


3ï¸âƒ£ Time-Series Benchmarking

ğŸ“Œ Overview

Benchmarks rolling mean/variance operations using:

* Pandas rolling
* NumPy stride tricks
* Numba JIT compilation

Generates:

* `results.csv` â€“ benchmark timings
* `benchmark_plot.png` â€“ log-log performance plot

ğŸ“‚ Structure


time_series_benchmark/
â”œâ”€â”€ benchmark.py          # Main benchmarking script
â”œâ”€â”€ timeseries_utils.py   # Rolling mean/variance, EWMA, FFT helpers


ğŸš€ Run

bash
python benchmark.py


4ï¸âƒ£ Stock Price Data Cleaning & Logistic Regression Modeling

ğŸ“Œ Overview

Processes 5 years of stock price data:

* Fills missing OHLCV data per company
* Removes outliers using IQR
* Generates rolling averages & daily returns
* Creates polynomial interaction features
* Encodes categorical companies
* Saves cleaned CSV

Then:

* Defines binary classification target: Will price go up next day?
* Trains **Logistic Regression (statsmodels)**
* Outputs odds ratios & confidence intervals

ğŸ“‚ Structure


stock_analysis/
â”œâ”€â”€ stock_cleaning.py     # Data cleaning & feature engineering
â”œâ”€â”€ stock_model.py        # Logistic regression modeling
â”œâ”€â”€ data/                 # Raw CSV
â””â”€â”€ Cleaned data/         # Processed CSV


ğŸš€ Run

bash
python stock_cleaning.py
python stock_model.py


